---
title: "PROJ2"
author: "Connor Glowacki"
date: "2023-09-18"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(MASS)
library(GGally)
library(leaps)
library(ggmap)
library(gridExtra)
library(ROCR)
library(faraway)
library(tidygeocoder)
library(leaflet)
library(geosphere)
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data \ Clean
```{r}
data <- read.csv("./project2/kc_house_data.csv", header = TRUE)
# data <- read.csv("./kc_house_data.csv", header = TRUE)


data$waterfront <- factor(data$waterfront)
data$view <- factor(data$view)
data$condition <- factor(data$condition)
data$grade <- factor(data$grade)
data$zipcode <- factor(data$zipcode)

extract_year_month <- function(date_string) {
  date_object <- strptime(date_string, "%Y%m%dT%H%M%S")
  year <- format(date_object, "%Y")
  month <- format(date_object, "%m")
  return(c(year, month))
}
data[c("year", "month")] <- t(sapply(data$date, extract_year_month))

data["age_at_sale"] <- as.integer(data$year) - as.integer(data$yr_built)

data["renovated"] <- ifelse(data$yr_renovated == 0, 0, 1)

data["expensive"] <- ifelse(data$price >= 700000, 1, 0)
data$expensive <- factor(data$expensive)

data["yr_since_renovation"] <- ifelse(
  data$yr_renovated == 0,
  data$age_at_sale,
  as.integer(data$year) - as.integer(data$yr_renovated)
)

# That addr is the space needle lol
seattle_addr <- tibble::tribble(
  ~name,                  ~addr,
  "Seattle",          "400 Broad St, Seattle, WA 98109"
)
lat_longs <- seattle_addr %>%
  geocode(addr, method = "osm", lat = latitude, long = longitude)

distance <- function(x, output) {
  current <- c(as.numeric(x["long"]), as.numeric(x["lat"]))
  seattle <- c(lat_longs$longitude, lat_longs$latitude)
  return(
    geosphere::distm(
      current,
      seattle,
      fun = geosphere::distHaversine
    )
  )
}
data$distSeattle <- apply(data, 1, distance)

data$zip_group <- substr(data$zipcode, 1, 4)

##  Omitting highly correlated predictors

# I think grade and zip_group should be removed too TBH
data_many <- subset(
  data,
  select = -c(id, date, price, zipcode, zip_group, lat, long, sqft_living15, sqft_lot15, sqft_above, grade)
)

data_more <- data[, c(
  "waterfront", "view", "yr_built", "renovated", "sqft_living",
  "floors", "condition", "expensive", "age_at_sale", "sqft_lot", "sqft_basement",
  "year", "month", "yr_since_renovation"
)
]
data_less <- data[, c(
  "waterfront", "view", "yr_built", "renovated", "sqft_living",
  "floors", "condition", "expensive", "age_at_sale"
)
]

set.seed(1)
sample <- sample.int(nrow(data_less), floor(.80 * nrow(data_less)), replace = FALSE)
train <- data_less[sample, ]
test <- data_less[-sample, ]
sample_more <- sample.int(nrow(data_more), floor(.80 * nrow(data_more)), replace = FALSE)
train_more <- data_more[sample_more, ]
test_more <- data_more[-sample_more, ]
sample_all <- sample.int(nrow(data), floor(.80 * nrow(data)), replace = FALSE)
train_all <- data[sample_all, ]
test_all <- data[-sample_all, ]
sample_many <- sample.int(nrow(data_many), floor(.80 * nrow(data_many)), replace = FALSE)
train_many <- data_many[sample_many, ]
test_many <- data_many[-sample_many, ]
```
## GEOCODE

```{r}
m <- leaflet(data) %>%
  addTiles() %>%
  addCircleMarkers(lng = data$long, lat = data$lat,  clusterOptions = markerClusterOptions())
m

# That addr is the space needle lol
seattle_addr <- tibble::tribble(
  ~name,                  ~addr,
  "Seattle",          "400 Broad St, Seattle, WA 98109"
)
lat_longs <- seattle_addr %>%
  geocode(addr, method = "osm", lat = latitude, long = longitude)

distance <- function(x, output) {
  current <- c(as.numeric(x["long"]), as.numeric(x["lat"]))
  seattle <- c(lat_longs$longitude, lat_longs$latitude)
  return(
    geosphere::distm(
      current,
      seattle,
      fun = geosphere::distHaversine
    )
  )
}
data$distSeattle <- apply(data, 1, distance)
```

## Graphs

```{r}

chart1 <- ggplot2::ggplot(data, aes(x = price)) +
  geom_density()
chart1

chart2 <- ggplot2::ggplot(data, aes(x = bedrooms, color = expensive)) +
  geom_density()

chart3 <- ggplot2::ggplot(data, aes(x = bathrooms, color = expensive)) +
  geom_density()

chart4 <- ggplot2::ggplot(train, aes(x = floors, color = expensive)) +
  geom_density()

chart5 <- ggplot2::ggplot(data, aes(x = grade, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart2, chart3, chart4, chart5, ncol = 2, nrow = 2)

chart6 <- ggplot2::ggplot(train, aes(x = waterfront, color = expensive)) +
  geom_density()

chart7 <- ggplot2::ggplot(train_more, aes(x = view, color = expensive)) +
  geom_density()

chart8 <- ggplot2::ggplot(train_more, aes(x = log(sqft_living), color = expensive)) +
  geom_density()

chart9 <- ggplot2::ggplot(train_more, aes(x = log(sqft_lot), color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart6, chart7, chart8, chart9, ncol = 2, nrow = 2)

chart10 <- ggplot2::ggplot(train_more, aes(x = yr_built, color = expensive)) +
  geom_density()

chart11 <- ggplot2::ggplot(data, aes(x = yr_renovated, color = expensive)) +
  geom_density()

chart12 <- ggplot2::ggplot(train_more, aes(x = renovated, color = expensive)) +
  geom_density()

chart13 <- ggplot2::ggplot(data, aes(x = zipcode, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart10, chart11, chart12, chart13, ncol = 2, nrow = 2)

chart14 <- ggplot2::ggplot(train_more, aes(x = year, color = expensive)) +
  geom_density()

chart15 <- ggplot2::ggplot(train_more, aes(x = month, color = expensive)) +
  geom_density()

chart16 <- ggplot2::ggplot(train_more, aes(x = log(sqft_basement), color = expensive)) +
  geom_density()

chart17 <- ggplot2::ggplot(train_more, aes(x = yr_since_renovation, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart14, chart15, chart16, chart17, ncol = 2, nrow = 2)

chart18 <- ggplot2::ggplot(train_all, aes(x = log(distSeattle), color = expensive)) +
  geom_density()

chart19 <- ggplot2::ggplot(train_all, aes(x = zip_group), color = expensive) +
  geom_density()

gridExtra::grid.arrange(chart18, chart19, ncol = 2, nrow = 1)

```

1. Displays of `bedrooms`, `bathrooms`, `floors`, `grade`
  - indicates that all of these may be useful in determining #expensive
  - HOWEVER, there is high correlation between these predictors
2. Displays of `waterfront`, `view`, `sqft_living`, `sqft_lot`
  - ?Seems to indicate that waterfront and view are not as useful
  - 


## Correlations 
```{r}
round(cor(data$yr_built, data$yr_renovated, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bedrooms, data$bathrooms, method = c("pearson", "kendall", "spearman")), 3)
round(cor(as.numeric(data$grade), data$bathrooms, method = c("pearson", "kendall", "spearman")), 3)
round(cor(as.numeric(data$grade), data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bedrooms, data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bathrooms, data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$age_at_sale, as.numeric(data$condition), method = c("pearson", "kendall", "spearman")), 3)
```


## Running Some Models

```{r}
full <- glm(expensive ~ ., family = binomial, data = train)
regnull <- glm(expensive ~ 1, family = binomial, data = train)
reduced1 <- glm(expensive ~ . - condition - waterfront, family = binomial, data = train)
reduced2 <- glm(expensive ~ . - condition - waterfront - renovated, family = binomial, data = train)
full_more <- glm(expensive ~ ., family = binomial, data = train_more)
regnull_more <- glm(expensive ~ 1, family = binomial, data = train_more)
reduced2_more <- glm(expensive ~ . - condition - waterfront - renovated, family = binomial, data = train_more)
full_more_reduced <- glm(expensive ~ . - yr_built - waterfront - year, family = binomial, data = train_more)
full_many <- glm(expensive ~ ., family = binomial, data = train_many)
regnull_many <- glm(expensive ~ 1, family = binomial, data = train_many)
full_many_reduced <- glm(formula = expensive ~ sqft_living + distSeattle + zip_group +
    view + sqft_basement + sqft_lot + condition + bedrooms +
    year + yr_renovated + renovated + floors + waterfront + month +
    age_at_sale + bathrooms, family = binomial, data = train_many)


summary(full)
summary(reduced1)
summary(reduced2)
summary(reduced2)

summary(full_more_reduced)
step(full)
step(reduced1)
step(reduced2)

step(reduced2, scope = list(lower = reduced2, upper = full), direction = "forward")
step(reduced2_more, scope = list(lower = reduced2_more, upper = full_more), direction = "forward")
step(regnull_many, scope = list(lower = regnull_many, upper = full_many), direction = "forward")

step(full_more)
```

```text
glm(formula = expensive ~ view + renovated + sqft_living + floors + 
    condition + age_at_sale + sqft_lot + sqft_basement + month +
    yr_since_renovation, family = binomial, data = train_more)
```

has the best AIC for a model selection but needs more analysis because that isn't what I expected. 

I thought `reduced2` would be best.

```text
glm(formula = expensive ~ view + yr_built + sqft_living + 
    floors + expensive + age_at_sale,
    family = binomial, data = train)
```

Going back and doing it will a the "many" set (which includes a new data point, distSeattle)

```text
glm(formula = expensive ~ sqft_living + distSeattle + zip_group + 
    view + sqft_basement + sqft_lot + condition + bedrooms +
    year + yr_renovated + renovated + floors + waterfront + month +
    age_at_sale + bathrooms, family = binomial, data = train_many)
```
## Con't w/ Best From AIC Selection

```{r}
aic_best <- glm(formula = expensive ~ view + renovated + sqft_living + floors +
    condition + age_at_sale + sqft_lot + sqft_basement + month +
    yr_since_renovation, family = binomial, data = train_more
)
summary(aic_best)
faraway::vif(aic_best)
```
```{r}
summary(reduced2)
faraway::vif(reduced2)
```
I don't really know what to make of the VIF being so bad
```{r}
summary(full_more_reduced)
faraway::vif(full_more_reduced)
```
```{r}
summary(full_many_reduced)
faraway::vif(full_many_reduced)
```
```{r}
calc_likelihood_ratio <- function(ful, red) {
  ts <- red$deviance - ful$deviance
  df <- length(attr(ful$terms, "term.labels")) - length(attr(red$terms, "term.labels"))
  ##pvalue
  p <- 1 - pchisq(ts, df)
  ##critical value
  crt <- qchisq(1 - 0.05, df)
  return(c(ts, df, p, crt))
}
```
```{r}
calc_likelihood_ratio(full, reduced2)
```

$$
H_{0}: \beta_{1} = 0 \\
H_{a}: \beta_{1} \neq 0
$$

G2 test stat is 43.09 with 2 DF, p-val is 2.354-09, and critical val is 7.815

p val small and TS > crt so we reject the null hypothesis

```{r}
calc_likelihood_ratio(full_more, reduced2_more)
```

Not that much different

```{r}
calc_likelihood_ratio(reduced2_more, reduced2)
```

Reject null but looks worse

```{r}
calc_likelihood_ratio(full_more, full_more_reduced)
```

Accept null

```{r}
calc_likelihood_ratio(full_many, full_many_reduced)
par(mfrow = c(2, 2))
plot(full_many_reduced)
acf(full_many_reduced$residuals, main = "ACF Plot of Residuals")
```

## LEVER

```{r}
hii <- lm.influence(full_many_reduced)$hat ##leverages
ext.student<-rstudent(full_many_reduced) ##ext studentized res
n <- nrow(data_many)
p <- 6
hii[hii > 2 * p / n]
sort(hii)
ext.student[abs(ext.student) > 3]
```

## Prediction

```{r}
logodds <- predict(reduced2, newdata = test)
head(logodds)

preds <- predict(reduced2, newdata = test, type = "response")
head(preds)
```

```{r}
logodds_more <- predict(full_more, newdata = test)
head(logodds)

preds_more <- predict(full_more, newdata = test, type = "response")
head(preds)
```

## Confusion
```{r}
table(test$expensive, preds > 0.5)
```
```{r}
# 1 -> TN
# 2 -> FN
# 3 -> FP
# 4 -> TP
calc_confunsion_metrics <- function(data, predictions, threshold) {
  ct <- table(data$expensive, predictions > threshold)
  n <- length(data)
  err_rate <- (ct[2] + ct[3]) / n
  acc <- (ct[1] + ct[4]) / n
  fpr <- ct[3] / (ct[1] + ct[3])
  fnr <- ct[2] / (ct[4] + ct[2])
  sensitivity <- ct[4] / (ct[4] + ct[2])
  specificity <- ct[1] / (ct[1] + ct[3])
  precision <- ct[4] / (ct[4] + ct[3])
  return(data.frame(err_rate, acc, fpr, fnr, sensitivity, specificity, precision))
}
```
```{r}
# test.new<-data.frame(test, preds, preds > 0.5)
cm <- calc_confunsion_metrics(test, preds, 0.5)
```

## ROC

```{r}
rates <- ROCR::prediction(preds, test$expensive)
roc_result <- ROCR::performance(rates, measure = "tpr", x.measure = "fpr")
plot(roc_result, main = "ROC Curve for Reduced Model")
lines(x = c(0, 1), y = c(0, 1), col = "red")
points(x = cm$fpr, y = cm$sensitivity, col = "blue", pch = 16)
```

Seems to indicate that we could bump the threshold up to 0.6 if needed

## AUC

```{r}
auc <- performance(rates, measure = "auc")
auc@y.values
```

With a value of `0.9031341`, does better than random guessing

## RANDOM

```{r}
Data<-read.table("./project2/students.txt", header=T, sep="")
##first column is index, remove it
Data<-Data[,-1]
##some NAs in data. Remove them
Data<-Data[complete.cases(Data),]
##convert categorical to factors. needed for contrasts
Data$Gender<-factor(Data$Gender)
Data$Smoke<-factor(Data$Smoke)
Data$Marijuan<-factor(Data$Marijuan)
Data$DrivDrnk<-factor(Data$DrivDrnk)
##set seed so results (split) are reproducible
set.seed(6021)
##evenly split data into train and test sets
sample.data<-sample.int(nrow(Data), floor(.50*nrow(Data)), replace = F)
sample.train<-Data[sample.data, ]
sample.test<-Data[-sample.data, ]
result <- glm(DrivDrnk ~ ., family = binomial, data = sample.train)
reduced<-glm(DrivDrnk~Smoke+Marijuan+DaysBeer, family=binomial, data=sample.train)
# faraway::vif(result)
calc_likelihood_ratio(result, reduced)
```