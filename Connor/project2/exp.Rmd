---
title: "PROJ2"
author: "Connor Glowacki"
date: "2023-09-18"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(MASS)
library(GGally)
library(leaps)
library(ggmap)
library(gridExtra)
library(ROCR)
library(faraway)
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data \ Clean
```{r}
data <- read.csv("./project2/kc_house_data.csv", header = TRUE)
# data <- read.csv("./kc_house_data.csv", header = TRUE)


data$waterfront <- factor(data$waterfront)
data$view <- factor(data$view)
data$condition <- factor(data$condition)
data$grade <- factor(data$grade)
data$zipcode <- factor(data$zipcode)

extract_year_month <- function(date_string) {
  date_object <- strptime(date_string, "%Y%m%dT%H%M%S")
  year <- format(date_object, "%Y")
  month <- format(date_object, "%m")
  return(c(year, month))
}
data[c("year", "month")] <- t(sapply(data$date, extract_year_month))

data["age_at_sale"] <- as.integer(data$year) - as.integer(data$yr_built)

data["renovated"] <- ifelse(data$yr_renovated == 0, 0, 1)

data["expensive"] <- ifelse(data$price >= 700000, 1, 0)
data$expensive <- factor(data$expensive)

data["yr_since_renovation"] <- ifelse(
  data$yr_renovated == 0,
  data$age_at_sale,
  as.integer(data$year) - as.integer(data$yr_renovated)
)

##  Omitting highly correlated predictors

data_more <- data[, c(
  "waterfront", "view", "yr_built", "renovated", "sqft_living",
  "floors", "condition", "expensive", "age_at_sale", "sqft_lot", "sqft_basement",
  "year", "month", "yr_since_renovation"
)
]
data_less <- data[, c(
  "waterfront", "view", "yr_built", "renovated", "sqft_living",
  "floors", "condition", "expensive", "age_at_sale"
)
]

set.seed(1)
sample <- sample.int(nrow(data_less), floor(.80 * nrow(data_less)), replace = FALSE)
train <- data_less[sample, ]
test <- data_less[-sample, ]
sample_more <- sample.int(nrow(data_more), floor(.80 * nrow(data_more)), replace = FALSE)
train_more <- data_more[sample_more, ]
test_more <- data_more[-sample_more, ]
# sample <- sample.int(nrow(data), floor(.80 * nrow(data)), replace = FALSE)
# train <- data[sample, ]
# test <- data[-sample, ]
```

## Graphs

```{r}
# GGally::ggpairs(data_cat_sub, lower = list(discrete=wrap("facethist", binwith=10)))
# chart1 <- ggplot2::ggplot(train, aes(x = species, fill = expensive)) +
#   geom_bar(position = "fill") +
#   labs(x = "Sex", y = "Proportion",
#        title = "Proportion of species by sex")
# chart1
chart2 <- ggplot2::ggplot(data, aes(x = bedrooms, color = expensive)) +
  geom_density()
# facet_wrap(train$species)

chart3 <- ggplot2::ggplot(data, aes(x = bathrooms, color = expensive)) +
  geom_density()

chart4 <- ggplot2::ggplot(train, aes(x = floors, color = expensive)) +
  geom_density()

chart5 <- ggplot2::ggplot(data, aes(x = grade, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart2, chart3, chart4, chart5, ncol = 2, nrow = 2)

chart6 <- ggplot2::ggplot(train, aes(x = waterfront, color = expensive)) +
  geom_density()
# facet_wrap(train$species)

chart7 <- ggplot2::ggplot(train_more, aes(x = view, color = expensive)) +
  geom_density()

chart8 <- ggplot2::ggplot(train_more, aes(x = sqft_living, color = expensive)) +
  geom_density()

chart9 <- ggplot2::ggplot(train_more, aes(x = log(sqft_lot), color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart6, chart7, chart8, chart9, ncol = 2, nrow = 2)

chart10 <- ggplot2::ggplot(train_more, aes(x = yr_built, color = expensive)) +
  geom_density()
# facet_wrap(train$species)

chart11 <- ggplot2::ggplot(data, aes(x = yr_renovated, color = expensive)) +
  geom_density()

chart12 <- ggplot2::ggplot(train_more, aes(x = renovated, color = expensive)) +
  geom_density()

chart13 <- ggplot2::ggplot(data, aes(x = zipcode, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart10, chart11, chart12, chart13, ncol = 2, nrow = 2)

chart14 <- ggplot2::ggplot(train_more, aes(x = year, color = expensive)) +
  geom_density()
# facet_wrap(train$species)

chart15 <- ggplot2::ggplot(train_more, aes(x = month, color = expensive)) +
  geom_density()

chart16 <- ggplot2::ggplot(train_more, aes(x = log(sqft_basement), color = expensive)) +
  geom_density()

chart17 <- ggplot2::ggplot(train_more, aes(x = yr_since_renovation, color = expensive)) +
  geom_density()

gridExtra::grid.arrange(chart14, chart15, chart16, chart17, ncol = 2, nrow = 2)
```

1. Displays of `bedrooms`, `bathrooms`, `floors`, `grade`
  - indicates that all of these may be useful in determining #expensive
  - HOWEVER, there is high correlation between these predictors
2. Displays of `waterfront`, `view`, `sqft_living`, `sqft_lot`
  - ?Seems to indicate that waterfront and view are not as useful
  - 


## Correlations 
```{r}
correlations <- round(cor(subset(train, select = -c(grade, expensive))), 3)
round(cor(data$yr_built, data$yr_renovated, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bedrooms, data$bathrooms, method = c("pearson", "kendall", "spearman")), 3)
round(cor(as.numeric(data$grade), data$bathrooms, method = c("pearson", "kendall", "spearman")), 3)
round(cor(as.numeric(data$grade), data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bedrooms, data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$bathrooms, data$sqft_living, method = c("pearson", "kendall", "spearman")), 3)
round(cor(data$age_at_sale, as.numeric(data$condition), method = c("pearson", "kendall", "spearman")), 3)
```


## Running Some Models

```{r}
full <- glm(expensive ~ ., family = binomial, data = train)
full_more <- glm(expensive ~ ., family = binomial, data = train_more)
regnull <- glm(expensive ~ 1, family = binomial, data = train)
regnull_more <- glm(expensive ~ 1, family = binomial, data = train_more)
summary(full)
reduced1 <- glm(expensive ~ . - condition - waterfront, family = binomial, data = train)
summary(reduced1)
reduced2 <- glm(expensive ~ . - condition - waterfront - renovated, family = binomial, data = train)
summary(reduced2)
reduced2_more <- glm(expensive ~ . - condition - waterfront - renovated, family = binomial, data = train_more)
summary(reduced2)

step(full)
step(reduced1)
step(reduced2)

step(reduced2, scope = list(lower = reduced2, upper = full), direction = "forward")
step(reduced2_more, scope = list(lower = reduced2_more, upper = full_more), direction = "forward")

step(full_more)
```

```text
glm(formula = expensive ~ view + renovated + sqft_living + floors + 
    condition + age_at_sale + sqft_lot + sqft_basement + month +
    yr_since_renovation, family = binomial, data = train_more)
```

has the best AIC for a model selection but needs more analysis because that isn't what I expected. I thought `reduced2` would be best.


## Con't w/ Best From AIC Selection

```{r}
aic_best <- glm(formula = expensive ~ view + renovated + sqft_living + floors +
    condition + age_at_sale + sqft_lot + sqft_basement + month +
    yr_since_renovation, family = binomial, data = train_more
)
summary(aic_best)
faraway::vif(aic_best)
```
```{r}
summary(reduced2)
faraway::vif(reduced2)
```
I don't really know what to make of the VIF being so bad

```{r}
calc_likelihood_ratio <- function(ful, red) {
  ts <- red$deviance - ful$deviance
  df <- length(attr(ful$terms, "term.labels")) - length(attr(red$terms, "term.labels"))
  ##pvalue
  p <- 1 - pchisq(ts, df)
  ##critical value
  crt <- qchisq(1 - 0.05, df)
  return(c(ts, df, p, crt))
}
```
```{r}
calc_likelihood_ratio(full, reduced2)
```

$$
H_{0}: \beta_{1} = 0 \\
H_{a}: \beta_{1} \neq 0
$$

G2 test stat is 43.09 with 2 DF, p-val is 2.354-09, and critical val is 7.815

p val small and TS > crt so we reject the null hypothesis

```{r}
calc_likelihood_ratio(full_more, reduced2_more)
```

Not that much different

```{r}
calc_likelihood_ratio(reduced2_more, reduced2)
```

## Prediction

```{r}
logodds <- predict(reduced2, newdata = test)
head(logodds)

preds <- predict(reduced2, newdata = test, type = "response")
head(preds)
```

## Confusion
```{r}
# 1 -> TN
# 2 -> FN
# 3 -> FP
# 4 -> TP
calc_confunsion_metrics <- function(data, predictions, threshold) {
  ct <- table(data$expensive, predictions > threshold)
  n <- length(data)
  err_rate <- (ct[2] + ct[3]) / n
  acc <- (ct[1] + ct[4]) / n
  fpr <- ct[3] / (ct[1] + ct[3])
  fnr <- ct[2] / (ct[4] + ct[2])
  sensitivity <- ct[4] / (ct[4] + ct[2])
  specificity <- ct[1] / (ct[1] + ct[3])
  precision <- ct[4] / (ct[4] + ct[3])
  return(data.frame(err_rate, acc, fpr, fnr, sensitivity, specificity, precision))
}
```
```{r}
# test.new<-data.frame(test, preds, preds > 0.5)
cm <- calc_confunsion_metrics(test, preds, 0.5)
```

## ROC

```{r}
rates <- ROCR::prediction(preds, test$expensive)
roc_result <- ROCR::performance(rates, measure = "tpr", x.measure = "fpr")
plot(roc_result, main = "ROC Curve for Reduced Model")
lines(x = c(0, 1), y = c(0, 1), col = "red")
points(x = cm$fpr, y = cm$sensitivity, col = "blue", pch = 16)
```

Seems to indicate that we could bump the threshold up to 0.6 if needed

## AUC

```{r}
auc <- performance(rates, measure = "auc")
auc@y.values
```

With a value of `0.9031341`, does better than random guessing

## RANDOM

```{r}
Data<-read.table("./project2/students.txt", header=T, sep="")
##first column is index, remove it
Data<-Data[,-1]
##some NAs in data. Remove them
Data<-Data[complete.cases(Data),]
##convert categorical to factors. needed for contrasts
Data$Gender<-factor(Data$Gender)
Data$Smoke<-factor(Data$Smoke)
Data$Marijuan<-factor(Data$Marijuan)
Data$DrivDrnk<-factor(Data$DrivDrnk)
##set seed so results (split) are reproducible
set.seed(6021)
##evenly split data into train and test sets
sample.data<-sample.int(nrow(Data), floor(.50*nrow(Data)), replace = F)
sample.train<-Data[sample.data, ]
sample.test<-Data[-sample.data, ]
result <- glm(DrivDrnk ~ ., family = binomial, data = sample.train)
reduced<-glm(DrivDrnk~Smoke+Marijuan+DaysBeer, family=binomial, data=sample.train)
# faraway::vif(result)
calc_likelihood_ratio(result, reduced)
```