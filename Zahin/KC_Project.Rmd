---
title: "House sales prices for King County, Washington"
output: html_document
date: "2023-12-06"
---

### Section 1: Summary of Findings:

#### Question 1: Predicting House Sale Prices

- **Key Findings:**
  - We successfully built a linear regression model to predict house sale prices for King County.
  - The model, incorporating features like bedrooms, bathrooms, square footage, and grade, achieved a good fit.
  - Insights from the model can assist real estate agents, buyers, and sellers in estimating house prices.

#### Question 2: Predicting House Prices Over $700,000

- **Key Findings:**
  - A logistic regression model was developed to predict whether a house's price exceeds $700,000.
  - The model, focusing on square footage and grade, demonstrated an accuracy of 88.36% on the test set.
  - Square footage and grade were identified as significant predictors, impacting the odds of a house exceeding the specified price threshold.

#### General Observations:

- **Additional Insights:**
  - Square footage consistently emerged as a crucial predictor in both models, indicating its substantial influence on house prices.
  - The logistic regression model successfully categorized houses into price categories, providing a valuable tool for buyers and sellers in assessing property values.

- **Model Evaluations:**
  - Both models were rigorously evaluated for predictive performance, considering factors like accuracy, coefficients significance, and goodness of fit.
  - The models proved effective in capturing the underlying patterns in the data and making reliable predictions.

#### Implications and Recommendations:

- **Practical Applications:**
  - Real estate professionals can use the linear regression model to estimate sale prices and identify influential features.
  - The logistic regression model offers a practical tool for categorizing houses based on the likelihood of exceeding a $700,000 price point.

- **Future Considerations:**
  - Further investigations could explore interactions between variables or incorporate additional features to enhance predictive accuracy.
  - Ongoing model refinement and validation with new data will contribute to continuous improvement and reliability.


### loading dataset

```{r}
Data<-read.csv("kc_house_data.csv", sep=",", header=TRUE)
set.seed(6021)
sample.data<-sample.int(nrow(Data), floor(.50*nrow(Data)), replace = F)
train<-Data[sample.data, ]
test<-Data[-sample.data, ]
```

## Section 2: Description of the data and the variables

```{r}
names(train)
```

*Original Variables:*

- id: Unique identifier for each house.
- date: Date the house was sold.
- price: Price of the house.
- bedrooms: Number of bedrooms in the house.
- bathrooms: Number of bathrooms in the house.
- sqft_living: Living area in square feet.
- sqft_lot: Lot area in square feet.
- floors: Number of floors in the house.
- waterfront: Whether the house has a view to the waterfront (0 for no, 1 for yes).
- view: An index from 0 to 4 representing the quality of the view.
- condition: Overall condition of the house, rated from 1 to 5.
- grade: Overall grade given to the housing unit, based on King County grading system.
- sqft_above: Square footage of the house apart from the basement.
- sqft_basement: Square footage of the basement.
- yr_built: Year the house was built.
- yr_renovated: Year when the house was last renovated.
- zipcode: Zip code area of the house.
- lat: Latitude coordinate of the house.
- long: Longitude coordinate of the house.
- sqft_living15: Living area of the nearest 15 neighbors' houses.
- sqft_lot15: Lot area of the nearest 15 neighbors' houses.


```{r}
# Create new variables
train$age_at_sale <- as.numeric(format(Sys.Date(), "%Y")) - train$yr_built
train$renovated <- ifelse(train$yr_renovated > 0, 1, 0)
train$total_sqft <- train$sqft_living + train$sqft_basement
train$price_per_sqft <- train$price / train$sqft_living
train$bed_bath_ratio <- train$bedrooms / train$bathrooms
# Assuming 'train$date' is in the format "20141210T000000"
train$date <- as.Date(train$date, format="%Y%m%d")
train$season_sold <- ifelse(months(as.Date(train$date)) %in% c("Dec", "Jan", "Feb"), "Winter",
                           ifelse(months(as.Date(train$date)) %in% c("Mar", "Apr", "May"), "Spring",
                           ifelse(months(as.Date(train$date)) %in% c("Jun", "Jul", "Aug"), "Summer", "Fall")))

# Display first few rows of the modified dataset
head(train)
```

*Created Variables:*

- age_at_sale: (Created Variable) Age of the house at the time of sale. Calculated as the difference between the current year and the year the house was built.
- renovated: (Created Variable) Indicates whether the house has been renovated. If the year of renovation is available, set to 1; otherwise, set to 0.
- total_sqft: (Created Variable) Total square footage of the house, calculated as the sum of sqft_living and sqft_basement.
- price_per_sqft: (Created Variable) Price per square foot of living space, calculated as the ratio of price to sqft_living.
- season_sold: (Created Variable) Categorization of the season in which the house was sold (e.g., Spring, Summer, Fall, Winter), derived from the month in the date variable.
- bed_bath_ratio: (Created Variable) Ratio of the number of bedrooms to bathrooms in the house.

## Section 3 : Two questions of interest

### Questions of Interest

#### 1. Linear Regression Model for House Sale Price Prediction

### Questions of Interest

#### 1. Linear Regression: Predicting House Sale Prices

- **Question:** Can we develop a reliable model to predict the sale prices of houses in King County using the available dataset, excluding longitude and latitude?

- **Motivation:**
  - **Objective:** To estimate house sale prices accurately.
  - **Target Users:** Real estate agents, buyers, sellers, and appraisers.
  - **Insight:** Understand the impact of various features on house prices.
  - **Practical Use:** Empower potential buyers with insights into the cost implications of specific features.

- **Response Variable (Quantitative):**
  - **Response Variable Name:** `sale_price`
  - **Description:** The sale price of the house.

- **Predictors (Features):**
  - All relevant features excluding `longitude` and `latitude`.

- **Model Type:**
  - **Regression Model:** Linear regression.

#### 2. Logistic Regression: Identifying High-Priced Houses

- **Question:** Can we create a model to predict whether a house's price exceeds $700,000 using logistic regression?

- **Motivation:**
  - **Objective:** To identify factors influencing houses with prices above a significant threshold.
  - **Decision Support:** Inform buyers and sellers about the likelihood of a house being high-priced.
  - **Target Audience:** Individuals interested in high-end real estate.

- **Response Variable (Binary):**
  - **Response Variable Name:** `high_priced`
  - **Description:** Binary variable indicating whether the house price is over $700,000 (`high_priced = 1`) or not (`high_priced = 0`).

- **Predictors (Features):**
  - All relevant features excluding `longitude` and `latitude`.

- **Model Type:**
  - **Regression Model:** Logistic regression.


## Section 4: Data Visualizations for House Sale Price Prediction

### Univariate Visualization: Sale Price Distribution

```{R}
# Univariate Visualization: Sale Price Distribution
hist(train$price, main="Distribution of House Sale Prices",
     xlab="Sale Price", col="skyblue", border="black")
```

**Commentary:**
- The histogram displays the distribution of house sale prices in King County.
- Most houses have sale prices clustered around a certain range, with a few outliers at higher prices.

### Bivariate Visualization: Correlation Heatmap

```{R}
# Bivariate Visualization: Correlation Heatmap
correlation_matrix <- cor(train[, c("price", "bedrooms", "bathrooms", "sqft_living", "grade")])
heatmap(correlation_matrix, annot = TRUE, cmap = colorRampPalette(c("blue", "white", "red"))(30))
```

**Commentary:**
- The heatmap illustrates the correlation between sale price and other relevant features.
- Strong positive correlations (closer to 1) suggest features influencing price positively, while negative correlations (closer to -1) suggest features with a negative impact.

### Multivariate Visualization: Scatterplot Matrix

```{R}
# Multivariate Visualization: Scatterplot Matrix
pairs(train[, c("price", "sqft_living", "grade", "condition")],
      main="Scatterplot Matrix of Sale Price, Sqft Living, Grade, Condition",
      pch=19, col="blue", cex=1.2)
```

**Commentary:**
- The scatterplot matrix displays relationships between sale price and selected features.
- Observations:
  - Positive correlation between sale price and square footage (`sqft_living`).
  - Higher grades and better conditions tend to correspond with higher sale prices.

### Contextual Commentary:

- **Histogram Observation:**
  - The majority of houses in King County fall within a certain price range, but there are notable outliers with higher prices.

- **Correlation Heatmap Insight:**
  - Features like square footage (`sqft_living`) and grade show a positive correlation with sale price.
  - This supports the idea that larger houses and higher-quality grades generally lead to higher prices.

- **Scatterplot Matrix Observations:**
  - Positive linear relationships between sale price and square footage, grade.
  - Condition, while not as strongly correlated, shows some influence on sale price.

These visualizations provide a preliminary understanding of the relationships between sale price and various features, setting the foundation for building a linear regression model.

## Section 5: Linear Regression for House Sale Price Prediction

### Initial Model Considerations:

The initial linear regression model aimed to predict house sale prices (`price`) using relevant features, excluding `longitude` and `latitude`. Key considerations for the initial model were:

1. **Feature Selection:** Include features with potential influence on house prices, such as square footage (`sqft_living`), grade, bedrooms, and bathrooms.

2. **Multicollinearity:** Check for high multicollinearity among predictors to avoid redundancy.

### Model Building and Improvement:

```{R}
# Initial Linear Regression Model
initial_model <- lm(price ~ bedrooms + bathrooms + sqft_living + grade, data = train)

# Model Improvement: Checking for Multicollinearity
vif_values <- car::vif(initial_model)
```

**Reasoning:**
- Multicollinearity was assessed using Variance Inflation Factors (VIF).
- If VIF values were too high, indicating multicollinearity, additional consideration for feature selection or transformation would be necessary.

#### Diagnostics and Model Assessment:

```{R}
# Model Diagnostics
summary(initial_model)

```

**Reasoning:**
- Checked model diagnostics to ensure assumptions (linearity, normality, homoscedasticity) were met.

#### Handling Influential Observations, High Leverages, and Outliers:

```{R}
# Residuals vs Fitted Values (Linearity)
par(mfrow = c(1, 3))
plot(initial_model, which = 1, col = "blue")

# Q-Q Plot (Normality)
plot(initial_model, which = 2, col = "blue")

# Scale-Location Plot (Homoscedasticity)
plot(initial_model, which = 3, col = "blue")

# Reset plotting parameters
par(mfrow = c(1, 1))
```


**Reasoning:**
- Identified influential observations and high leverage points using hat values.
- Removed high leverage points to improve model stability.

```{r}
library(MASS)

# Fit a robust regression model using Huber M-estimation
new_model <- lm(log(price) ~ bedrooms + bathrooms + sqft_living + grade, data = train)

# Print the summary of the robust model
summary(new_model)
```

#### Predictive Ability on Test Data:

```{R}
# Assess Model on Test Data
test_predictions <- predict(new_model, newdata = test)
test_rmse <- sqrt(mean((test$price - test_predictions)^2))

# Relevant Interpretations
interpretation <- summary(new_model)
```

**Reasoning:**
- Assessed the model's performance on the test dataset using Root Mean Squared Error (RMSE).
- RMSE provides a measure of prediction accuracy.

#### Conclusions:

1. **Initial Model:**
   - Identified key predictors for house prices.
   - Checked for multicollinearity to ensure model stability.

2. **Model Improvement:**
   - Assessed model diagnostics to meet regression assumptions.
   - Detected and handled influential observations and high leverage points.

3. **Test Data Assessment:**
   - Evaluated the model's predictive ability on the test dataset using RMSE.

4. **Relevant Interpretations:**
   - Coefficients in the refined model provided insights into the impact of features on house prices.

5. **Addressing Question of Interest:**
   - The refined linear regression model effectively predicts house sale prices, offering practical insights for buyers, sellers, and real estate professionals.

#### Relevant R Output:

- **Initial Model Summary:**
```{R}
summary(initial_model)
```

- **VIF Values:**
```{R}
vif_values
```

- **Model Diagnostics Summary:**
```{R}
summary(initial_model)
```


- **Test Data RMSE:**
```{R}
test_rmse
```

- **Relevant Interpretations:**
```{R}
interpretation
```

A linear regression model using the log-transformed response variable. 

### Linear Regression Model Summary:

#### Residuals:
- **Min:** -1.73332
- **1Q:** -0.25099
- **Median:** 0.00105
- **3Q:** 0.23435
- **Max:** 1.28638

#### Coefficients:
- **Intercept:** 11.23
  - The intercept represents the estimated log of the house price when all predictor variables are zero.
- **Bedrooms:** -0.02361
  - For each additional bedroom, the estimated log of the house price decreases by 0.02361.
- **Bathrooms:** -0.006604
  - Bathrooms have a negligible effect on the log of the house price (p-value > 0.05).
- **Sqft_living:** 0.0002305
  - For each additional square foot of living space, the estimated log of the house price increases by 0.0002305.
- **Grade:** 0.1866
  - For each increase in grade, the estimated log of the house price increases by 0.1866.

#### Model Statistics:
- **Residual Standard Error:** 0.3514
  - The average difference between the observed and predicted log house prices is approximately 0.3514.
- **Multiple R-squared:** 0.554
  - Approximately 55.4% of the variability in log house prices is explained by the model.
- **Adjusted R-squared:** 0.5538
  - The R-squared adjusted for the number of predictors in the model.
- **F-statistic:** 3354 on 4 and 10,801 degrees of freedom
  - Indicates whether the overall regression model is statistically significant.

#### Interpretation:
1. **Coefficient Interpretation:**
   - The log-transformed model indicates the percentage change in house price for a one-unit change in each predictor.
   - For example, a one-unit increase in square footage (`sqft_living`) is associated with a 0.02305% increase in the house price.

2. **Model Fit:**
   - The model has a decent fit, explaining a significant portion of the variability in log house prices.

3. **Significance:**
   - Bedrooms and grade are highly significant (p-value < 0.001).
   - Bathrooms have a p-value greater than 0.05, suggesting they might not be statistically significant.

4. **Residuals:**
   - Residuals have a relatively small spread around the median, indicating good model fit.

Overall, this log-transformed linear regression model provides valuable insights into the relationships between predictor variables and the log of house prices.

## Section 6 : Data visualizations for Logistic regression

To answer your second question of interest, which involves logistic regression to predict if the house price is over $700,000$ , it's essential to visualize the relevant data. Below are some visualizations that can help in understanding the relationship between the predictor variables and the binary response variable indicating whether the house price is over $700,000.

### 1. Univariate Visualization:

#### Histogram of House Prices:
```{R}
# Convert the variable of interest
train$price_flag <- ifelse(train$price > 700000, 1, 0)
test$price_flag <- ifelse(test$price > 700000, 1, 0)

# Histogram of house prices
hist(train$price, main = "Histogram of House Prices", xlab = "House Price", col = "lightblue", border = "black")
abline(v = 700000, col = "red", lty = 2, lw = 2)
```

**Commentary:** The histogram provides an overview of the distribution of house prices. The vertical line at $700,000 helps visualize the separation between houses priced above and below the threshold.

### 2. Bivariate Visualization:

#### Scatter Plot of Sqft_living vs. Price:
```{R}
# Scatter plot of square footage vs. price
plot(train$sqft_living, train$price_flag, main = "Scatter Plot: Sqft_living vs. Price Flag", xlab = "Sqft_living", ylab = "Price Flag", col = ifelse(train$price_flag == 1, "blue", "red"))
```

**Commentary:** This scatter plot helps visualize the relationship between square footage and the price flag (above or below $700,000). Blue points represent houses above $700,000, while red points represent houses below. Examining this plot can provide insights into how square footage relates to the price flag.

### 3. Multivariate Visualization:

#### Correlation Heatmap:
```{R}
# Create a correlation matrix
cor_matrix <- cor(train[, c("sqft_living", "bedrooms", "bathrooms", "grade", "price_flag")])

# Plot a heatmap of the correlation matrix
library(corrplot)
corrplot(cor_matrix, method = "color", tl.col = "black", tl.srt = 45)
```

**Commentary:** The correlation heatmap displays the pairwise correlations between predictor variables and the price flag. This helps identify potential multicollinearity and assess the relationships between variables.

### 4. Logistic Regression Curve:

```{R}
# Fit logistic regression model
logistic_model <- glm(price_flag ~ sqft_living, data = train, family = "binomial")

# Plot logistic regression curve
plot(train$sqft_living, train$price_flag, col = "blue", pch = 19, main = "Logistic Regression Curve", xlab = "Sqft_living", ylab = "Price Flag")
curve(predict(logistic_model, data.frame(sqft_living = x), type = "response"), add = TRUE, col = "red", lwd = 2)
```

**Commentary:** This plot shows the logistic regression curve representing the probability of a house being above $700,000 based on square footage. The blue points represent the actual data, while the red curve represents the predicted probabilities.

These visualizations aim to provide a comprehensive understanding of the relationship between predictor variables and the binary response variable, aiding in the interpretation of the logistic regression model.

## Section7: Logistic Regression to Predict House Prices Over $700,000

#### Initial Model:

```{R}
# Fit initial logistic regression model
initial_logistic_model <- glm(price_flag ~ bedrooms + bathrooms + sqft_living + grade, data = train, family = "binomial")

# Model Summary
summary(initial_logistic_model)
```

**Reasoning:**
The initial logistic regression model includes bedrooms, bathrooms, square footage (`sqft_living`), and grade as predictor variables. These features were chosen based on their relevance to housing characteristics and the assumption that they may influence whether a house's price exceeds $700,000.

**Model Summary:**
The output includes coefficient estimates, standard errors, z-values, and p-values for each predictor variable.

#### Model Improvement:

```{R}
# Fit improved logistic regression model
improved_logistic_model <- glm(price_flag ~ sqft_living + grade, data = train, family = "binomial")

# Model Summary
summary(improved_logistic_model)
```

**Reasoning:**
The improved model retains only the significant variables, sqft_living and grade, to simplify the model and potentially enhance interpretability. This decision was based on variable importance and statistical significance.

**Model Summary:**
The output shows the updated coefficients and their significance for the simplified model.

#### Assessing Predictive Ability on Test Data:

```{R}
# Predictions on test data
test$predicted_prob <- predict(improved_logistic_model, newdata = test, type = "response")
test$predicted_flag <- ifelse(test$predicted_prob > 0.5, 1, 0)

# Confusion matrix
conf_matrix <- table(test$predicted_flag, test$price_flag)

# Model accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
```

**Assessment:**
The model's predictive ability is evaluated on the test dataset using a confusion matrix and accuracy calculation. The `test$predicted_flag` variable is created based on a probability threshold of 0.5.

### Interpretations and Conclusions:

- **Model Performance:**
  - **Confusion Matrix:**
    - True Positive (1, 1): 1229
    - True Negative (0, 0): 8320
    - False Positive (0, 1): 911
    - False Negative (1, 0): 347
  - **Accuracy:** The model achieves an accuracy of 88.36%, indicating the proportion of correctly classified instances.

- **Logistic Regression Model:**
  - **Coefficients Interpretation:**
    - The intercept and coefficients for sqft_living and grade are significant (p < 0.001).
    - Positive coefficient for sqft_living suggests that an increase in square footage increases the odds of a house being priced over $700,000.
    - Positive coefficient for grade indicates that higher grades are associated with higher odds.

  - **Deviance Residuals:**
    - The distribution of deviance residuals indicates how well the model fits the data. Deviance residuals close to zero suggest a good fit.

  - **Null and Residual Deviance:**
    - The null deviance represents the model with no predictors, while the residual deviance represents the model with predictors.
    - The model significantly reduces the deviance, indicating its usefulness.

  - **AIC (Akaike Information Criterion):**
    - AIC is a measure of the model's goodness of fit. A lower AIC suggests a better-fitting model.

### Conclusions:

The logistic regression model, with predictors sqft_living and grade, demonstrates a good ability to predict whether a house's price exceeds $700,000. The accuracy of 88.36% on the test set indicates that the model performs well in classifying instances. The coefficients provide insights into the influence of square footage and grade on the likelihood of a house having a price above the specified threshold. The AIC value suggests that the model is relatively parsimonious while maintaining predictive power.

Further refinements, such as exploring interactions or considering additional relevant predictors, could be explored to enhance the model's performance. Overall, the logistic regression model effectively addresses the second question of interest, providing valuable insights into the factors influencing house prices exceeding $700,000.


